# 7. 한글 검색 확장 기능
엘라스틱서치로 검색 사이트 구축시 한글 처리에 많은 문제가 있다. 한글 형태소 분석기를 이용하면 많은 문제를 해결할 수 있지만 유니코드의 특성상 키보드 입력에 대한 실시간 처리는 형태소 분석기만으로는 완벽하게 처리하기 불가능하다.

엘라스틱서치에서 기본적으로 제공하는 Suggest API가 키워드 자동완성을 지원하지만 한글 키워드를 대상으로 할 때는 정상적으로 동작하지 않기 때문에 한글 키워드를 지원하려면 직접 자동완성을 구현해야 한다.

## 7.1 Suggest API 소개
사용자가 키워드를 잘못 입력했거나 검색한 결과가 없을 경우 어떻게 보여주어야 할까? 검색엔진 특성상 분리된 텀과 완전히 일치하지 않으면 검색 결과로 제공되지 않을 가능성이 매우 크다. 이러한 경우 검색 결과의 만족도를 높이기 위해 엘라스틱서치는 도큐먼트 내에 존재하는 단어를 대상으로 비슷한 키워드를 변경해서 제시하는 교정 기능을 제공한다.
가령 검색어의 철자를 잘못 입력 하는 경우 어떻게든 비슷한 내용을 보여 줄 수 있는 방안을 찾아야 하는데 그 방법중 하나가 단어의 철자를 수정해서 다른 단어를 제공하거나 제안된 내용을 보여주는 맞춤법 검사기(Spell Checker) 기능이다.

* Term Suggest API : 추천 단어 제안, 잘못된 철자에 대해 해당 인덱스의 특정 필드에서 가장 유사한 단어를 추천해주는 오타 교정 방법
* Completion Suggest API : 자동완성 제안, 사용자가 입력을 완료하기 전에 자동완성을 사용하여 검색어를 예측해서 보여준다. (영문에서는 잘 동작하지만 한글에서는 X)
* Phrase Suggest API : 추천 문장 제안
* Context Suggest API : 추천 문맥 제안

### Term Suggest API
이것은 편집거리를 사용해 비슷한 단어를 제안한다. 편집거리 척도란 어떤 문자열이 다른 문자열과 얼마나 비슷한가를 편집거리를 사용해 알아볼 수 있다. 두 문자열 사이의 편집거리는 하나의 문자열을 다른 문자열로 바꾸는 데 필요한 편집 횟수를 말한다.

측정 과정을 진행할 때 한 문자열을 다른 문자열로 바꾸는데 필요한 삽입, 삭제, 치환 연산의 총 수행 횟수의 합계를 편집거리라 한다. 예시(319~321p)

한글의 경우 Term Suggest를 사용해도 데이터가 추천되지 않는다. 하지만 한글의 자소를 분해해서 문서를 처리한 후 색인할 경우 영문과 동일하게 추천 기능을 구현하는 것이 가능해진다. (자바카페의 플러그인 사용)

### Completion Suggest API
검색 사이트에서는 일반적으로 사용자의 검색을 효율적으로 돕기 위해 자동완성 기능을 제공한다. 자동완성은 글자가 입력될 때마다 검색 결과를 보여줘야 하기 때문에 응답속도가 매우 중요하다. Completion Suggest API를 사용하게 되면 엘라스틱서치 내부적으로 FST(검색어가 모두 메모리에 로드되는 구조)를 사용한다.

자동완성 기능을 사용하기 위해서는 데이터 타입을 `completion`으로 설정해서 인덱스를 생성해야 한다. completion을 사용하려면 필드에 데이터를 넣을 때 검색이 가능해지는 형태로 가공해서 넣어야 한다. 예) 부분일치를 하고 싶다면 원하는 부분을 분리해서 배열형태로 만들어야 한다. 예시(322~328p)

Completion Suggest API가 전방일치 방식밖에 지원하지 않기 때문에 색인시 데이터를 가공해야 한다.

## 7.2 맞춤법 검사기
### Term Suggester API를 이용한 오타 교저
Term Suggester API를 이용하면 인덱스 내에 있는 단어를 이용해 비슷한 단어가 추천된다. 기본적으로 한글의 경우는 잘 동작하지 않으므로 한글에 적용할 수 있는 플러그인을 별도로 설치한다. 

```
# 자바 카페 플러그인 설치
$ wget https://github.com/javacafe-project/elastic-book-etc/raw/master/plugin/javacafe-analyzer-6.4.3.zip

# 플러그인을 엘라스틱 서치에 설치
$ ./bin/elasticsearch-plugin install file://<플러그인 절대경로>/javacafe-analyzer-6.4.3.zip

# 엘라스틱 서치에 설치된 플러그인 목록 조화
$ ./bin/elasticsearch-plugin list

# 필터
* javacafe_chosung : 한글 초성 분석 필터
* javacafe_jamo : 한글 자모 분석 필터
* javacafe_eng2kor : 영한 오타 변환 필터
* javacafe_kor2eng : 한영 오타 변환 필터
* javacafe_spell : 한글 맞춤법 검사 필터
```

예제(330~333p)

1) 인덱스 생성 : 인덱스 생성시 필터 항목에 javacafe_spell 필터를 추가한다.
2) 매핑 설정 : 매핑에 자동 완성이 적용될 suggest 필드를 정의하고 analyzer 속성에 외부 분석기를 사요앟ㄴ다.
3) 오타 교정 데이터 색인
4) 오타 교정 API 요청

사용자가 입력한 단어와 비슷한 단어를 찾기 위해 javacafe_spell 필터는 내부적으로 색인된 모든 데이터를 자소 단위로 분해해서 생성한다. 그리고 요청된 검색어도 자소로 분해해서 비슷한 데이터를 찾는다. 이때는 모든 데이터가 자소 단위로 분해됐기 때문에 편집거리 계산이 가능해진다.

### 한영/영한 오타 교정
한글 검색어를 영문 자판으로 설정해 두고 검색하거나 영문 검색어를 한글 자판으로 설정해 놓고 검색하는 경우가 있다. 이런 경우의 오타를 교정할 때는 다음 두 가지 방식중 어떤 방식을 사용자에게 제공할지 생각해야 한다.
1. 해당 단어를 추천만 하는 방법
2. 해당 단어를 추천하고 추천한 단어로 검색 결과를 보여주는 방법

검색 서비스에 따라 위 두 가지 방법을 선택적으로 사용하고 있다.

예제(337~343p)

1) 인덱스 생성 : 한영 오차 교정과 영한 오차 교정을 위해 javacafe_kor2eng 필터와 javacafe_eng2kor 필터를 추가한다.
2) 매핑 설정
3) 오타 교정 데이터 색인
4) 오타 교정 API 요청

## 7.3 한글 키워드 자동완성
엘라스틱서치에서는 자동완성을 지원하기 위해 Complection Suggest API를 제공한다. 영문처리에는 적합하지만 한글을 처리하는데는 적합하지 않다.

### Completion Suggest API를 이용한 한글 자동완성
344~350p
```
# 인덱스 생성
PUT /ac_test
{
    "settings": {
        "index": {
            "number_of_shards": 5,
            "number_of_replicas": 1
        }
    }
}

# 매핑 설정
PUT /ac_test/_mapping/ac_test
{
    "properties": {
        "itemSrc": {   //매칭 검색 용도로 사용하는 필드
            "type": "keyword"
        },
        "itemCompletion": {     //자동완성 용도로 사용하는 필드
            "type": "completion"
        }
    }
}
```

### Suggest API를 이용한 한글 자동완성의 문제점
1. 부분 일치 불가 : 키워드의 일부분으로는 자동완성의 결과가 제공되지 않는다. Completion Suggest API가 내부적으로 Prefix 방식의 매칭만 지원하고 있어 키워드의 시작 부분이 반드시 일치해야 결과로 제공된다.
2. 한글 초성 검색 불가 : 한글의 초성 검색이 가능해지려면 한글의 자모 분석이 먼저 이뤄져야 한다. Completion Suggest API의 경우 한글 자모 분석을 지원하지 않기 때문에 초성 검색을 구현하는 것은 불가능하다.
3. 한글 자모 검색 불가

### 직접 구현해보는 한글 자동완성
Completion Suggest API를 이용하면 간단하게 자동완성 기능을 구현할 수 있으나, 한글 키워드를 대상으로 제공하기에는 아쉬운 점이 많다. 따라서 Completion Suggest API에 의존하지 않고 직접 구현해보자

__루씬의 분석 기능 활용하기__

자동 완성 기능은 키보드 입력이 발생할 때마다 결과를 제공해야 하기 때문에 빠른 속도를 보장해야 한다. 엘라스틱서치는 이러한 동작 특성상 내부적으로 메모리를 적극적으로 활용한다. Completion Suggest API로 생성된 인덱스의 전체 데이터를 메모리에 올려 캐시로 생성하고 요청이 올 때마다 메모리에서 연산을 수행하는 방식으로 동작한다.
하지만 이것은 Prefix 매칭만 지원하기 때문에 루씬의 기능을 활용하지 못한다.

루씬을 이용하는 경우 루씬에서 제공하는 각종 분석 기능을 활용하는 것이 가능해진다. 하지만 루씬이 제공하는 분석기능은 메모리 연산이 아니기 때문에 속도 측면에서는 일부 손해를 보게된다.

__확장된 Ngram 검색 적용하기__

키워드 검색시 다양한 단어의 조합으로 이뤄진 복합 명사가 대부분이다. 이런 경우 사용자가 검색어를 입력할 때 원하는 단어의 일부분만 입력해도 자동완성으로 해당 키워드를 제공해야 한다.

부분 일치를 가장 간단히 구현하는 방법으로 Ngram을 이용하는 방법이 있다. Ngram 분석기는 엘라스틱서치에서 기본적으로 제공하는 분석기이기 때문에 손쉽게 사용할 수 있다. Ngram은 단어를 한 글자씩 잘라내어 토큰화하기 때문에 누락 없는 부분일치를 구현하기에 안성맞춤이다.

* Ngram 분석기 : 음적 단위로 토큰을 생성, 재현율은 높으나 정확도는 떨어짐, 첫 음절 기준으로 max_gram에서 지정한 길이만큼 토큰을 생성한다.
* Edge Ngram 분석기 : 대부분 Ngram과 유사하게 동작, 지정한 토크나이저의 특성에 따라 Ngram이 일어난다.
* Edge Ngram Back Analyzer : Edge Ngram과 반대로 동작하는 토크나이저를 사용, 옵션으로 "side:back"을 반드시 설정해야 한다.

359~374p

### 한글 초성 검색 적용하기
375~381p

### 한글 자모 검색 적용하기
"신혼"이라는 단어를 컴색시 6번의 키 입력이 발생한다. 자동완성은 키를 입력시마다 결과를 제공해야 하는데 자모 검색을 이용하면 6번의 키 입력이 일어날 때마다 모두 "신혼"이라는 키워드를 결과로 얻을 수 있어야 한다. 하지만 한글 키 입력의 특성상 입력중에 '싢'같은 겹자모가 생성될 수 있어 자동완성을 구현하는 데 어려움이 있다.

만족스러운 자동완성을 제공하기 위해서는 이런 겹자모 문제를 해결해야 한다. 382~389p

## 7.4 자바카페 플러그인
엘라스틱서치에서 제공하지 않는 기능을 추가하려면 플러그인을 사용해야 한다. 

한글의 경우 엘라스틱서치에서 기본적으로 잘 처리되지 않기 때문에 확장이 반드시 필요하다. 

### 한글 유니코드의 이해
한글은 유니코드에서 0x0000~0xFFFF에 정의돼 있다. 한글 자모는 유니코드 0x1100~0x11FF까지의 범위를 가지며 총 256자로 구성된다. 한글 호환용 자모는 유니코드 0x3130~0x318F까지의 범위를 가지며 총 96개의 공간중 94자를 정의해서 구성된다. 

현대 한글에서 표현할 수 있는 글자 수는 총 11,172자다. 모든 글자는 Hangul Syllables에 코드로 정의돼 있다.

### 한글 자모 분석 필터(javacafe_jamo)
javacafe_jamo 필터는 한글을 자모 단위로 분해해서 제공하는 분석 필터다. 토크나이저에 의해 텀으로 분리된 단어를 글자수별로 파싱해서 자모 분석을 시작한다. 만약 처리할 글자가 유니코드 범위에 해당하지 않는 경우에는 분해하지 않고 무시한다.

색인할 때와 검색할때 토큰을 분리하는 기준이 서로 다르다. 이렇게 하는 이유는 일반적으로 자모 검색은 자동완성 형태의 검색에 많이 이용되고 한 글자씩 입력되는 과정에서 입력 순서에 따라 항상 검색이 가능하도록 색인할 때 키 입력 순서에 따른 자모 분석 결과를 제공해야 하기 때문이다.

### 한글 초성 분석 필터(javacafe_chosung)
javacafe_chosung 필터는 한글을 자모 단위로 분해한 후 초성만 추출해서 제공하는 분석 필터다.  자모 분석 필터와 마찬가지로 초성 분석 필터도 색인용 분석기와 검색용 분석기를 각각 정의한다.

### 영한 오타 변한 필터(javacafe_eng2kor)
javacafe_eng2kor 필터는 한영 키에 의한 영문 오타를 한글로 교정해주는 필터다. 구현원리는 한글 키보드에 대응되는 영문 키보드 값을 정의해서 서로 변환해주는 방식이다.

### 한영 오타 변환 필터(javacafe_kor2eng)
javacafe_kor2eng 필터는 한글 오타를 영문으로 교정해주는 필터다. 영한 오타 필터의 반대 방식으로 동작한다.

### 스펠링 체크 필터(javacafe_spell)
javacafe_spell 필터는 맞춤법 검사기 내부에서 사용하는 필터다. 한글을 먼저 자모 형태로 분해해야 하기 때문에 필요하다.