# 6. 고급 검색
## 6.1 한글 형태소 분석기 사용하기
엘라스틱서치에서 한글 문서를 효율적으로 검색하게 하려면 한글 형태소 분석기를 활용해 직접 분서기를 구성해야 한다. 한글은 다른 언어와 달리 형태소를 분석하는 과정이 쉽지 않다.

사용 가능한 형태소 분석기로는 상용 제품도 있고, 오픈 소스로 공개된 것들도 다수 있다. 그리고 필요하다면 자체적으로 형태소 분석기를 개발해서 사용하는 것도 가능하다.

### 은전한닢 형태소 분석기
은전한닢 형태소 분석기는 자바 인터페이스와 스칼라 인터페이스의 두 종류를 제공한다. 시스템 사전에 등록돼 있는 사전을 기반으로 동작하며, 복합명사와 활용어의 원형 찾기가 가능하다. 현재 엘라스틱서치에서 가장 보편적으로 사용하는 한글 형태소 분석기다.

설치 및 설정 방법 (278~279p)

__사전 추가__ : 한글에는 복합명사가 있다. 예)삼성 + 전자, 은전한닢에서는 사용자가 등록하는 사전을 제공하는데 이런 사전을 '사용자 사전'이라 한다. 사용자 사전은 term과 가중치(weight) 형태로 구성돼 있고, 가중치의 값이 작을수록 우선순위는 높아진다 예)삼성전자,-100 / 삼성,-50 / 전자,-50

### Nori 형태소 분석기
루씬에서 공식적으로 제공되는 한글 형태소 분석기로 6.4 버전에서 공식 릴리즈 됐다. 기존 형태소 분석기에 비해 30% 이상 빠르고 메모리 사용량도 현저하게 줄었으며, 시스템 전반에 영향을 주지 않게 최적화됐다.

설치 방법 (282p)

1. nori_tokenizer - 형태소를 토큰 형태로 분리하는 데 사용한다. 
   * decompound_mode : 토크나이저가 복합명사를 처리하는 방식을 결정한다. (none 복합 명사로 분리X / discard 복합명사로 분리, 원본 데이터 삭제 / mixed 복합명사로 분리 원본 데이터 유지)
   * user_dictionary : Nori 토크나이저는 내부적으로 세종 말뭉치와 mecab-ko-dic 사전을 사용한다. user_dictionary를 이용하여 사용자가 정의한 명사를 사전에 추가로 등록할 수 있다. config/userdic_ko.txt 파일에 명사를 추가하면 된다.
2. nori_part_of_speech - 이 토큰 필터는 품사 태그 세트와 일치하는 토큰을 찾아 제거하는 토큰 필터다. 이를 이용하면 역색인될 명사를 선택적으로 고를 수 있다.(사용하고 싶지 않은 형태소 제거 가능) stoptags 라는 파라미터를 통해 분리된 토큰에서 제거할 특정 형태소를 지정하는 것이 가능하다. (286~290p)
3. nori_readingform - 이 필터는 문서에 존재하는 한자를 한글로 변경하는 역할을 하는 필터다. (290~293p)

### 트위터 형태소 분석기
트위터에서 한글을 처리하기 위해 개발한 형태소 분석기다. 초기에는 트위터에서 직접 개발했으나 현재는 오픈소스로 개발되고 있다. (293~295p)

트위터 한글 형태소 분석기는 엘라스틱서치 6.1.1 버전까지만 사용 가능하도록 릴리스돼 있다. 

설치 방법 (296p)

__사전 추가__ : 엘라스틱서치 서버의 plugins/elasticsearch-analysis-openkoreantext/dic 디렉터리 안에 사용자가 작성한 텍스트 파일을 추가하면 된다. 기본적으로 한 줄 단위로 처리되며 단어 사이에 띄어쓰기가 포함된 단어는 인식하지 않는다.

__인덱스 설정__ : 플러그인 컴포넌트는 Character Filter, Tokenizer Filter, Analyzer로 구성돼 있으며, 필요에 따라 구성해서 사용하면 된다.